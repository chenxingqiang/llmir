==== Multi-Query Attention Benchmark ====
Config: batch=2, seqLen=2048, contextLen=2048, heads=12, dim=64

Standard Multi-Head Attention:
  Time: 11652.1 ms per run
  Performance: 2.2116 GFLOPs/sec
  Memory: 48 MB

Multi-Query Attention:
  Time: 11334.4 ms per run
  Performance: 1.1368 GFLOPs/sec
  Memory: 26 MB
  Memory Reduction: 45.8333%

Speedup: 1.02803x

Output Difference (MHA vs MQA):
  Max Difference: 0.12577
  Average Difference: 0.00192741
