version: '3'

services:
  llama31-benchmark:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ./results:/app/results
      - $HOME/.cache/huggingface:/root/.cache/huggingface
    environment:
      - HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}
    command: -c "./run_llama31_benchmark.sh --batch-sizes 1 --seq-lens 128 --repetitions 2"
    platform: linux/amd64  # 使用x86_64模拟，因为某些CUDA库在ARM上不可用
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu] 