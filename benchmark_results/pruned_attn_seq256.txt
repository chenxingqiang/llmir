==== Pruned Attention Benchmark ====
Config: batch=2, seqLen=256, contextLen=256, heads=8, dim=64
Threshold: 0.01, TopK: 128

Standard Attention:
  Time: 107.248 ms per run
  Performance: 2.50294 GFLOPs/sec

Threshold-Pruned Attention:
  Time: 63.8695 ms per run
  Performance: 1.64361 GFLOPs/sec
  Pruning Ratio: ~60.8932%
  Speedup: 1.67918x

Top-K Pruned Attention:
  Time: 102.621 ms per run
  Performance: 1.30789 GFLOPs/sec
  Pruning Ratio: 50%
  Speedup: 1.04509x

Output Differences:
  Threshold-Pruned vs Standard:
    Max Difference: 0.106437
    Average Difference: 0.00222855
  Top-K Pruned vs Standard:
    Max Difference: 0.0163267
    Average Difference: 0.00108958
