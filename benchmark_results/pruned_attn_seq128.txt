==== Pruned Attention Benchmark ====
Config: batch=2, seqLen=128, contextLen=128, heads=8, dim=64
Threshold: 0.01, TopK: 128

Standard Attention:
  Time: 23.7098 ms per run
  Performance: 2.83043 GFLOPs/sec

Threshold-Pruned Attention:
  Time: 18.9852 ms per run
  Performance: 2.76477 GFLOPs/sec
  Pruning Ratio: ~21.7842%
  Speedup: 1.24885x

Top-K Pruned Attention:
  Time: 24.3965 ms per run
  Performance: 2.75076 GFLOPs/sec
  Pruning Ratio: 0%
  Speedup: 0.971852x

Output Differences:
  Threshold-Pruned vs Standard:
    Max Difference: 0.100679
    Average Difference: 0.0010587
  Top-K Pruned vs Standard:
    Max Difference: 1.86265e-08
    Average Difference: 8.90748e-10
