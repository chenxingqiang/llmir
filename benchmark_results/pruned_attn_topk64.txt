==== Pruned Attention Benchmark ====
Config: batch=2, seqLen=512, contextLen=512, heads=8, dim=64
Threshold: 0.01, TopK: 64

Standard Attention:
  Time: 454.521 ms per run
  Performance: 2.36236 GFLOPs/sec

Threshold-Pruned Attention:
  Time: 232.074 ms per run
  Performance: 0.904707 GFLOPs/sec
  Pruning Ratio: ~80.4461%
  Speedup: 1.95852x

Top-K Pruned Attention:
  Time: 368.548 ms per run
  Performance: 0.36418 GFLOPs/sec
  Pruning Ratio: 87.5%
  Speedup: 1.23327x

Output Differences:
  Threshold-Pruned vs Standard:
    Max Difference: 0.10374
    Average Difference: 0.00227502
  Top-K Pruned vs Standard:
    Max Difference: 0.029678
    Average Difference: 0.00415518
